---
title: "`r params$doc_title`"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
description: This template is a Text Analysis Interactive Dashboard. 
  Remember to change the title to your liking.
  PLEASE Knit it with Parameters!!!
output: 
  flexdashboard::flex_dashboard:
    vertical_layout: scroll
    orientation: columns
params:
  username:
    label: "NSSP Username: "
    value: ""
    input: text
    placeholder: "username"
  password:
    label: "NSSP Password: "
    value: ""
    input: password
    placeholder: "password"
  start_date:
    label: "Enter Start Date: "
    value: !r lubridate::ceiling_date(Sys.Date() - 90, unit = "1 week")
    input: date
  end_date:
    label: "Enter End Date: "
    value: !r Sys.Date()
    input: date
  has_been_E: 
    label: "Has Been Emergency: "
    value: true
  data_source:
    label: "Data Source: "
    value: Chief Complaint Query Validation
    input: select 
    choices: [Chief Complaint Query Validation, Facility Location (Full Details)]
  site:
    label: "Limit to Site (only if using full details): "
    value: "All"
    input: select
    choices: !r stn <- tempfile(fileext =".rds"); download.file(file.path("https://raw.githubusercontent.com", "cdcgov", "Rnssp-rmd-templates", "master", "text_mining", "skeleton", "nca_hosp.rds"), destfile = stn); dplyr::pull(readRDS(stn), site_name)
    multiple: no
  age_groups: 
    label: "Age Groups: "
    value: "All Ages"
    input: select
    choices: !r agrp <- tempfile(fileext =".rds"); download.file(file.path("https://raw.githubusercontent.com", "cdcgov", "Rnssp-rmd-templates", "master", "text_mining", "skeleton", "essagegrps.rds"), destfile = agrp); dplyr::pull(readRDS(agrp), display_name)
    multiple: yes
  definition: 
    label: "Syndrome Definition: " 
    value: "None (Custom CCDD Query)"
    input: select
    choices: !r fl <- tempfile(fileext =".rds"); download.file(file.path("https://raw.githubusercontent.com", "cdcgov", "Rnssp-rmd-templates", "master", "text_mining", "skeleton", "syndef.rds"), destfile = fl); definitions <- tibble::add_row(readRDS(fl), syndrome = "None (Custom CCDD Query)", query_logic = "", .before = 1); dplyr::pull(definitions, syndrome)
  ccdd_query: 
    label: "CCDD Query: "
    value: ""
    input: text
    placeholder: "Free Text Query e.g.: ^[;/ ]J10^,OR,^[;/ ]J.10^"
  doc_title:
    label: "Title: "
    value: Text Mining Template (NSSP-ESSENCE)
    input: text
---

```{r setup, include = FALSE}
## Libraries ----
library(Rnssp)
library(tidyverse)
library(tidytext)
library(kableExtra)
library(knitr)
library(janitor)
library(wesanderson)
library(MMWRweek)
library(openxlsx)
library(lubridate)
library(grid)
library(gridExtra)
library(shiny)
library(flexdashboard)
library(plotly)
library(widyr)
library(igraph)
library(visNetwork)
library(ggpubr)
library(ggthemes)
library(flextable)
library(ggraph)
library(DT)

```

```{r set_end_start_dates, echo=FALSE, message=FALSE, include=FALSE}
endDate <- format(params$end_date, "%d%b%Y")
startDate <- format(params$start_date, "%d%b%Y")
hasBeenE <- as.numeric(params$has_been_E)
definition <- params$definition
```

```{r set_nssp_user_profile, echo=FALSE, message=FALSE, include=FALSE}
## Set NSSP user profile
myProfile <- Credentials$new(
  username = params$username,
  password = params$password
)
```

```{r ESSENCE data pull, echo=FALSE, message = FALSE, warning = FALSE, results = 'hide'}
definition_pattern <- as.character(str_match(definition, pattern = "CCDD Category|Subsyndrome|Syndrome|None \\(Custom CCDD Query\\)"))

if (definition_pattern == "CCDD Category") {
  definition_string <- str_replace_all(str_remove_all(tolower(definition), "ccdd category: "), " ", "%20")
  definition_type <- "&ccddCategory="
  grouping_system <- "essencesyndromes"
}

if (definition_pattern == "Subsyndrome") {
  definition_string <- str_replace_all(str_remove_all(tolower(definition), "subsyndrome: "), " ", "")
  definition_type <- "&medicalGrouping="
  grouping_system <- "chiefcomplaintsubsyndromes"
}

if (definition_pattern == "Syndrome") {
  definition_string <- str_replace_all(str_remove_all(tolower(definition), "syndrome: "), " ", "%20")
  definition_type <- "&syndrome="
  grouping_system <- "essencesyndromes"
}

if (definition_pattern == "None (Custom CCDD Query)") {
  definition_string <- str_replace_all(params$ccdd_query, "\\^", "%5E") %>%
    str_replace_all(" ", "%20") %>%
    str_replace_all("\\[", "%5B") %>%
    str_replace_all("\\]", "%5D")
  definition_type <- "&ccddFreeText="
  grouping_system <- "essencesyndromes"
}

if (params$site != "All") {
  site_id <- readRDS("nca_hosp.rds") %>%
    filter(site_name == params$site) %>%
    pull(site_id)
}

if (params$data_source == "Chief Complaint Query Validation") {
  url <- paste0("https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate, "&timeResolution=weekly&percentParam=noPercent", definition_type, definition_string, "&userId=2362&datasource=va_erccdd&aqtTarget=DataDetails&detector=nodetectordetector&startDate=", startDate, "&hasBeenE=", hasBeenE)
} else if (params$data_source == "Facility Location (Full Details)") {
  if (params$age_groups == "All Ages") {
    if (params$site == "All") {
      url <- paste0("https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate, "&percentParam=noPercent&datasource=va_hosp&startDate=", startDate, "&medicalGroupingSystem=", grouping_system,"&userId=2362&aqtTarget=DataDetails", definition_type, definition_string, "&geographySystem=hospital&detector=nodetectordetector&timeResolution=daily&hasBeenE=", hasBeenE, "&field=Date&field=WeekYear&field=ChiefComplaintOrig&field=ChiefComplaintParsed&field=DischargeDiagnosis&field=CCDD")
    } else {
      url <- paste0("https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate, "&percentParam=noPercent&datasource=va_hosp&startDate=", startDate, "&medicalGroupingSystem=", grouping_system, "&userId=2362&site=", site_id, "&aqtTarget=DataDetails", definition_type, definition_string, "&geographySystem=hospital&detector=nodetectordetector&timeResolution=daily&hasBeenE=", hasBeenE, "&field=Date&field=WeekYear&field=ChiefComplaintOrig&field=ChiefComplaintParsed&field=DischargeDiagnosis&field=CCDD")
    }
  } else {
    age_group_string <- params$age_groups %>%
      str_replace_all(": ", "=") %>%
      str_replace_all(" ", "") %>%
      paste(collapse = "&age") %>%
      str_remove_all("AgeGroup|Reporting") %>%
      str_replace_all("Distribute", "distribute") %>%
      str_replace_all("School", "school") %>%
      paste0("age", .)
    
    if (grepl("age\\d{1}", age_group_string)) {
      age_group_string <- str_replace_all(age_group_string, "age", "ageGroup")
    }
    
    if (params$site == "All") {
      url <- paste0(
        "https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate,
        "&percentParam=noPercent&datasource=va_hosp&startDate=", startDate, "&medicalGroupingSystem=", grouping_system, "&userId=2362&aqtTarget=DataDetails", definition_type, definition_string, "&geographySystem=hospital&detector=nodetectordetector&timeResolution=daily&hasBeenE=", hasBeenE, "&", age_group_string, "&field=Date&field=WeekYear&field=ChiefComplaintOrig&field=ChiefComplaintParsed&field=DischargeDiagnosis&field=CCDD&field=Age"
      )
    } else {
      url <- paste0(
        "https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate,
        "&percentParam=noPercent&datasource=va_hosp&startDate=", startDate, "&medicalGroupingSystem=", grouping_system , "&userId=2362&site=", site_id, "&aqtTarget=DataDetails", definition_type, definition_string, "&geographySystem=hospital&detector=nodetectordetector&timeResolution=daily&hasBeenE=", hasBeenE, "&", age_group_string, "&field=Date&field=WeekYear&field=ChiefComplaintOrig&field=ChiefComplaintParsed&field=DischargeDiagnosis&field=CCDD&field=Age"
      )
    }
  }
}
# Data Pull from NSSP-ESSENCE
api_data_json <- myProfile$get_api_data(url)
api_data <- api_data_json$dataDetails

data <- api_data %>%
  clean_text() %>%
  separate(week_year, c("year", "week"), sep = "-", remove = TRUE) %>%
  mutate(
    week = as.numeric(week),
    year = as.numeric(year)
  ) %>%
  filter(!is.na(week)) %>%
  mutate(
    date = MMWRweek2Date(year, week, MMWRday = NULL),
    linenumber = row_number(),
    month = round_date(date, "month")
  )
```

```{r data and dictionary import, echo = FALSE, warning = FALSE, message = FALSE}

dictionary <- openxlsx::read.xlsx("ICD10v2.xlsx") %>%
  as_tibble() %>%
  clean_names() %>%
  add_row(code = "U07.1", description = "COVID-19, virus identified") %>%
  add_row(code = "U071", description = "COVID-19, virus identified") %>%
  add_row(code = "M79.10", description = "Myalgia, unspecified site") %>%
  add_row(code = "M7910", description = "Myalgia, unspecified site") %>%
  add_row(code = "Z11.52", description = "Encounter for screening for COVID-19") %>%
  add_row(code = "Z1152", description = "Encounter for screening for COVID-19") %>%
  add_row(code = "Z20.822", description = "Contact with and (suspected) exposure to COVID-19") %>%
  add_row(code = "Z20822", description = "Contact with and (suspected) exposure to COVID-19") %>%
  add_row(code = "Z86.16", description = "Personal history of COVID-19") %>%
  add_row(code = "Z8616", description = "Personal history of COVID-19") %>%
  add_row(code = "M35.81", description = "Multisystem inflammatory syndrome (MIS)") %>%
  add_row(code = "M3581", description = "Multisystem inflammatory syndrome (MIS)") %>%
  add_row(code = "M35.89", description = "Other specified systemic involvement of connective tissue") %>%
  add_row(code = "M3589", description = "Other specified systemic involvement of connective tissue") %>%
  add_row(code = "J12.82", description = "Pneumonia due to coronavirus disease") %>%
  add_row(code = "J1282", description = "Pneumonia due to coronavirus disease") %>%
  arrange(code)

```

Background
==========================================================================

Column 
-----------------------------------------------------------------------

### Purpose  

The purpose of this interactive dashboard is to summarize the chief complaint text and diagnosis codes as part of an initial description of the content of these fields in *existing* syndromes or categories. This report template is available via the `Rnssp` library and allows users to input a list of parameters, including: 

* AMC username and password (securely encrypted to a user profile object of class `Credentials`)
* Start and end date of query
* Has been Emergency: TRUE/FALSE option for limiting to emergency department visits 
* Data source: options include the Chief Complaint Query Validation (CCQV) data source or Facility Location (Full Details)
* Syndrome definition: CCDD Category, Subsyndrome, or Syndrome. Currently includes all definitions within ESSENCE as of June 17th, 2021

The data source used in this dashboard is the Chief Complaint Query Validation (CCQV) data source in NSSP-ESSENCE, which includes the chief complaint and discharge diagnosis fields, and does not include facility location, patient location, or other demographic information. This data source was created with the Syndromic Community of Practice (CoP) so that users can test and create new syndrome categories using a large corpus of chief complaint and diagnosis code data that includes more variation than would be present in any one site.  Some sites have opted out of contributing their data to the Query Validation data source, including Arizona, Idaho, Illinois, Marion County, Indiana, Massachusetts, North Dakota, and Ohio.

### Interactive Visualizations 

The visualizations in this dashboard include total weekly volume of encounters, the 200 most frequent n-gram frequencies of chief complaint terms and discharge diagnosis codes, term co-occurrence network graphs for the ChiefComplaintParsed and CCDD fields, a chief complaint term correlation network graph, and n-grams with significant increases or decreases in occurrence over time. Potential clusters or groupings of terms are visualized by node color and can be selected from the "Select by group" drop down menu. All interactive widgets were produced with the `plotly` and `visNetwork` packages which provide hovering functionality such as displaying data point values, ICD-10 code descriptions, and co-occurrence frequencies. 

### `r paste("Query Details:", str_squish(str_remove_all(definition, "CCDD Category|Syndrome|Subsyndrome|:")))`

```{r query, echo = FALSE, warning = FALSE, message = FALSE}

if (params$age_groups == "All Ages") {
  field <- str_match(definition, pattern = "CCDD Category|Subsyndrome|Syndrome|None \\(Custom CCDD Query\\)")
  
  if (params$ccdd_query != "") {
    query <- params$ccdd_query
    
    data.frame(Fields = field, Query = str_replace_all(query, pattern = "\\^", "\\\\^")) %>%
      kable() %>%
      kable_styling() %>%
      scroll_box(width = "1000px", height = "300px")
  } else {
    query <- readRDS("syndef.rds") %>%
      filter(syndrome == definition) %>%
      pull(query_logic)
    
    data.frame(Fields = field, Query = str_replace_all(query, pattern = "\\^", "\\\\^")) %>%
      kable() %>%
      kable_styling() %>%
      scroll_box(width = "1000px", height = "300px")
  }
} else {
  field <- c(str_match(definition, pattern = "CCDD Category|Subsyndrome|Syndrome|None \\(Custom CCDD Query\\)"), as.character(str_match(params$age_group, pattern = "([[:alnum:]]*|\\-|\\s*)*(?=:)")[, 1])) %>%
    unique()
  
  if (params$ccdd_query != "") {
    query <- params$ccdd_query
    
    data.frame(Fields = field, Query = str_replace_all(query, pattern = "\\^", "\\\\^")) %>%
      kable() %>%
      kable_styling() %>%
      scroll_box(width = "1000px", height = "300px")
  } else {
    query <- readRDS("syndef.rds") %>%
      filter(syndrome == definition) %>%
      pull(query_logic)
    
    age_groups <- as.character(str_match(params$age_group, pattern = "\\d{2}-\\d{2}|\\d{2}\\+")) %>%
      ifelse(length(.) == 1, ., paste(., collapse = ", "))
    
    data.frame(Fields = field, Query = c(str_replace_all(query, pattern = "\\^", "\\\\^"), age_groups)) %>%
      kable() %>%
      kable_styling() %>%
      scroll_box(width = "1000px", height = "300px")
  }
}
```

Column 
-----------------------------------------------------------------------

### Total Number of Encounters

```{r total encounters, echo = FALSE, warning = FALSE, message = FALSE}

n_encounters <- format(nrow(data), big.mark = ",")
valueBox(n_encounters, icon = "fa-hospital")
```

### Date Range

```{r date range, echo = FALSE, warning = FALSE, message = FALSE}

range <- paste(format(as.Date(min(data$date)), "%B %d, %Y"), "to", format(as.Date(max(data$date)), "%B %d, %Y"))

valueBox(range, icon = "fa-calendar", color = "orange")

```

### Total Weekly Volume of Encounters from Query Validation Data Source \nNSSP-ESSENCE

```{r total volume, echo = FALSE, warning = FALSE, message = FALSE}

data %>%
  count(date) %>%
  plot_ly(
    x = ~date,
    y = ~n,
    type = "scatter",
    mode = "lines+markers",
    hoverinfo = "text",
    text = ~ paste(
      "</br><b>Date:</b>", date,
      "</br><b>Encounters:</b>", n
    )
  ) %>%
  layout(
    xaxis = list(title = "MMWR Week Date", rangemode = "tozero"),
    yaxis = list(title = "Encounters", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

Chief Complaint {data-navmenu="Character and Token Length of CC and DD Fields"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Characters in Chief Complaint Field  

```{r mean characters CC, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths <- data %>%
  mutate(
    lengthCC = str_count(chief_complaint_parsed),
    tokensCC = sapply(strsplit(chief_complaint_parsed, " "), length),
    lengthDD = str_count(discharge_diagnosis),
    tokensDD = sapply(strsplit(discharge_diagnosis, " "), length)
  ) %>%
  group_by(date) %>%
  summarise(
    MeanCharLengthCC = mean(lengthCC, na.rm = TRUE),
    MedianCharLengthCC = median(lengthCC, na.rm = TRUE),
    MeanTknLengthCC = mean(tokensCC, na.rm = TRUE),
    MedianTknLengthCC = median(tokensCC, na.rm = TRUE),
    MeanCharLengthDD = mean(lengthDD, na.rm = TRUE),
    MedianCharLengthDD = median(lengthDD, na.rm = TRUE),
    MeanTknLengthDD = mean(tokensDD, na.rm = TRUE),
    MedianTknLengthDD = median(tokensDD, na.rm = TRUE),
    N = n()
  ) %>%
  ungroup()

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MeanCharLengthCC,
    type = "scatter",
    mode = "lines",
    name = "Mean"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Characters", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

### Weekly Median Number of Characters in Chief Complaint Field 

```{r median characters CC, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MedianCharLengthCC,
    type = "scatter",
    mode = "lines",
    name = "Median"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Characters", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Tokens in Chief Complaint Field 

```{r mean tokens CC, echo = FALSE, error = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MeanTknLengthCC,
    type = "scatter",
    mode = "lines",
    name = "Mean"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Tokens", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

### Weekly Median Number of Tokens in Chief Complaint Field 

```{r median tokens CC, echo = FALSE, error = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MedianTknLengthCC,
    type = "scatter",
    mode = "lines",
    name = "Mean"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Tokens", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

Discharge Diagnosis {data-navmenu="Character and Token Length of CC and DD Fields"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Characters in Discharge Diagnosis Field  

```{r mean characters DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MeanCharLengthDD,
    type = "scatter",
    mode = "lines",
    name = "Mean"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Characters", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

### Weekly Median Number of Characters in Discharge Diagnosis Field 

```{r median characters DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MedianCharLengthDD,
    type = "scatter",
    mode = "lines",
    name = "Median"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Characters", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Tokens in Discharge Diagnosis Field 

```{r mean tokens DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MeanTknLengthDD,
    type = "scatter",
    mode = "lines",
    name = "Mean"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Tokens", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

### Weekly Median Number of Tokens in Discharge Diagnosis Field 

```{r median tokens DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>%
  plot_ly(
    x = ~date,
    y = ~MedianTknLengthDD,
    type = "scatter",
    mode = "lines",
    name = "Mean"
  ) %>%
  layout(
    xaxis = list(title = "Week"),
    yaxis = list(title = "Tokens", rangemode = "tozero")
  ) %>%
  config(displayModeBar = FALSE)
```

Unigram {data-navmenu="N-gram Frequencies"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Chief Complaint  

```{r CC unigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

unnested_cc_unigrams <- data %>%
  unnest_tokens(word, chief_complaint_parsed) %>%
  filter(!is.na(word)) %>%
  filter(!grepl("\\d+", word)) %>%
  filter(nchar(word) > 2) %>%
  anti_join(stop_words)

ccngram <- unnested_cc_unigrams %>%
  count(word, sort = TRUE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    word = str_to_upper(word),
    word = factor(word, levels = unique(word)[order(n, decreasing = TRUE)])
  )

ccngram %>%
  plot_ly(
    x = ~n,
    y = ~word,
    type = "bar",
    orientation = "h",
    hoverinfo = "text",
    text = ~ paste(
      word,
      "<br> Frequency: ", n
    )
  ) %>%
  layout(
    title = "Top 200 Single Term Frequencies of Chief Complaint Parsed",
    xaxis = list(title = "Frequency"),
    yaxis = list(autorange = "reversed", title = "Word")
  ) %>%
  config(displayModeBar = FALSE)
```

Column 
-----------------------------------------------------------------------

### Discharge Diagnosis 

```{r DD unigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

unnested_dd_unigrams <- data %>%
  unnest_tokens(word, discharge_diagnosis) %>%
  anti_join(stop_words)

ddngram <- unnested_dd_unigrams %>%
  count(word, sort = TRUE) %>%
  ungroup() %>%
  top_n(200) %>%
  mutate(word = toupper(word)) %>%
  left_join(dictionary, by = c("word" = "code")) %>%
  distinct() %>%
  mutate(
    word = factor(word, levels = unique(word)[order(n, decreasing = TRUE)])
  )

ddngram %>%
  plot_ly(
    x = ~n,
    y = ~word,
    type = "bar",
    orientation = "h",
    hoverinfo = "text",
    text = ~ paste(
      word, ": ", description,
      "<br> Frequency: ", n
    )
  ) %>%
  layout(
    title = "Top 200 Single Term Frequencies of Discharge Diagnosis",
    xaxis = list(title = "Frequency"),
    yaxis = list(autorange = "reversed", title = "Word")
  ) %>%
  config(displayModeBar = FALSE)
```

Bigram {data-navmenu="N-gram Frequencies"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Chief Complaint 

```{r CC bigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

unnested_cc_bigrams <- data %>%
  unnest_tokens(bigram, chief_complaint_parsed, token = "ngrams", n = 2) %>%
  separate(bigram, into = c("word1", "word2"), sep = " ", remove = FALSE) %>%
  filter(
    !is.na(bigram),
    !word1 %in% stop_words$word & !word2 %in% stop_words$word,
    nchar(word1) > 2 & nchar(word2) > 2,
    !grepl("\\d+", word1) & !grepl("\\d+", word2)
  )

cc_bigram_top200 <- unnested_cc_bigrams %>%
  count(bigram, sort = TRUE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    bigram = str_to_upper(bigram),
    bigram = factor(bigram, levels = unique(bigram)[order(n, decreasing = TRUE)])
  )

cc_bigram_top200 %>%
  plot_ly(
    x = ~n,
    y = ~bigram,
    type = "bar",
    orientation = "h",
    hoverinfo = "text",
    text = ~ paste(
      bigram,
      "<br> Frequency: ", n
    )
  ) %>%
  layout(
    title = "Top 200 Bigram Frequencies of Chief Complaint Parsed",
    xaxis = list(title = "Frequency"),
    yaxis = list(autorange = "reversed", title = "Bigram")
  ) %>%
  config(displayModeBar = FALSE)
```

Column 
-----------------------------------------------------------------------

### Discharge Diagnosis

```{r DD bigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

unnested_dd_bigrams <- data %>%
  unnest_tokens(bigram, discharge_diagnosis, token = "ngrams", n = 2) %>%
  filter(!is.na(bigram)) %>%
  separate(bigram, c("code1", "code2"), remove = FALSE) %>%
  rowwise() %>%
  mutate(bigramID = list(c(code1, code2))) %>%
  mutate(bigramID = paste(sort(bigramID), collapse = "-"))

ddngram <- unnested_dd_bigrams %>%
  count(bigramID, sort = TRUE) %>%
  ungroup() %>%
  top_n(200) %>%
  slice(1:200) %>%
  separate(bigramID, c("code1", "code2"), sep = "-", remove = FALSE) %>%
  mutate(
    code1 = toupper(code1),
    code2 = toupper(code2)
  ) %>%
  mutate(bigram = paste(code1, code2, sep = " ")) %>%
  left_join(dictionary, by = c("code1" = "code")) %>%
  left_join(dictionary, by = c("code2" = "code")) %>%
  rename(
    description1 = description.x,
    description2 = description.y
  ) %>%
  mutate(bigram = factor(bigram, levels = unique(bigram)[order(n, decreasing = TRUE)])) %>%
  distinct()

ddngram %>%
  plot_ly(
    x = ~n,
    y = ~bigram,
    type = "bar",
    orientation = "h",
    hoverinfo = "text",
    text = ~ paste(
      code1, ": ", description1,
      "<br>", code2, ": ", description2,
      "<br> Frequency: ", n
    )
  ) %>%
  layout(
    title = "Top 200 Bigram Frequencies of Discharge Diagnosis",
    xaxis = list(title = "Frequency"),
    yaxis = list(autorange = "reversed", title = "Bigram")
  ) %>%
  config(displayModeBar = FALSE)
```

Trigram {data-navmenu="N-gram Frequencies"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Chief Complaint  

```{r CC trigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

ccngram <- data %>%
  unnest_tokens(trigram, chief_complaint_parsed, token = "ngrams", n = 3) %>%
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ", remove = FALSE) %>%
  filter(
    !is.na(trigram),
    !word1 %in% stop_words$word & !word2 %in% stop_words$word & !word3 %in% stop_words$word,
    nchar(word1) > 2 & nchar(word2) > 2 & nchar(word3) > 2,
    !grepl("\\d+", word1) & !grepl("\\d+", word2) & !grepl("\\d+", word3)
  ) %>%
  count(trigram, sort = TRUE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    trigram = str_to_upper(trigram),
    trigram = factor(trigram, levels = unique(trigram)[order(n, decreasing = TRUE)])
  )

ccngram %>%
  plot_ly(
    x = ~n,
    y = ~trigram,
    type = "bar",
    orientation = "h",
    hoverinfo = "text",
    text = ~ paste(
      trigram,
      "<br> Frequency: ", n
    )
  ) %>%
  layout(
    title = "Top 200 Trigram Frequencies of Chief Complaint Parsed",
    xaxis = list(title = "Frequency"),
    yaxis = list(autorange = "reversed", title = "Trigram")
  ) %>%
  config(displayModeBar = FALSE)
```

Column 
-----------------------------------------------------------------------

### Discharge Diagnosis  

```{r DD trigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

ddngram <- data %>%
  unnest_tokens(trigram, discharge_diagnosis, token = "ngrams", n = 3) %>%
  filter(!is.na(trigram)) %>%
  separate(trigram, c("code1", "code2", "code3"), remove = FALSE) %>%
  rowwise() %>%
  mutate(trigramID = list(c(code1, code2, code3))) %>%
  mutate(trigramID = paste(sort(trigramID), collapse = "-")) %>%
  count(trigramID, sort = TRUE) %>%
  ungroup() %>%
  top_n(200) %>%
  slice(1:200) %>%
  separate(trigramID, c("code1", "code2", "code3"), sep = "-", remove = FALSE) %>%
  mutate(
    code1 = toupper(code1),
    code2 = toupper(code2),
    code3 = toupper(code3)
  ) %>%
  mutate(trigram = paste(code1, code2, code3, sep = " ")) %>%
  left_join(dictionary, by = c("code1" = "code")) %>%
  left_join(dictionary, by = c("code2" = "code")) %>%
  left_join(dictionary, by = c("code3" = "code")) %>%
  rename(
    description1 = description.x,
    description2 = description.y,
    description3 = description
  ) %>%
  mutate(trigram = factor(trigram, levels = unique(trigram)[order(n, decreasing = TRUE)])) %>%
  distinct()

ddngram %>%
  plot_ly(
    x = ~n,
    y = ~trigram,
    type = "bar",
    orientation = "h",
    hoverinfo = "text",
    text = ~ paste(
      code1, ": ", description1,
      "<br>", code2, ": ", description2,
      "<br>", code3, ": ", description3,
      "<br> Frequency: ", n
    )
  ) %>%
  layout(
    title = "Top 200 Trigram Frequencies of Discharge Diagnosis",
    xaxis = list(title = "Frequency"),
    yaxis = list(autorange = "reversed", title = "Trigram")
  ) %>%
  config(displayModeBar = FALSE)
```

Chief Complaint Co-occurrence {data-navmenu="Term Network Graphs"} 
=======================================================================

### Chief Complaint Parsed Term Co-occurrence Network Graph

```{r CC network, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 10}

edges <- unnested_cc_unigrams %>%
  pairwise_count(word, linenumber, sort = TRUE, upper = FALSE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    item1 = toupper(item1),
    item2 = toupper(item2)
  )

colnames(edges) <- c("from", "to", "title")

nodes <- unique(c(edges$from, edges$to)) %>%
  as_tibble()
colnames(nodes) <- "label"
nodes$id <- nodes$label
nodes$font.size <- rep(30, nrow(nodes))

a <- 1
b <- 20
c <- min(edges$title)
d <- max(edges$title)

edges$width <- a + ((b - a) / (d - c)) * (edges$title - c)
graph <- graph_from_data_frame(edges, directed = FALSE)
cluster <- cluster_louvain(graph)
cluster_df <- data.frame(as.list(membership(cluster)))
cluster_df <- as.data.frame(t(cluster_df))
cluster_df$label <- rownames(cluster_df)
nodes <- left_join(nodes, cluster_df, by = "label")
colnames(nodes)[4] <- "group"

visNetwork(nodes, edges, height = "500px", width = "100%") %>%
  visIgraphLayout() %>%
  visInteraction(zoomView = FALSE) %>%
  visNodes(
    shape = "dot",
    color = list(background = "#0085AF", border = "#013848", highlight = "#FF8000"),
    shadow = list(enabled = TRUE, size = 10)
  ) %>%
  visEdges(color = list(color = "#0085AF", highlight = "#C62F4B")) %>%
  visOptions(
    selectedBy = "group",
    highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE),
    nodesIdSelection = TRUE
  ) %>%
  visLayout(randomSeed = 2001)
```

Chief Complaint and Discharge Diagnosis Co-occurrence {data-navmenu="Term Network Graphs"} 
=======================================================================

### CCDD Term Co-occurrence Network Graph

```{r CCDD network, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 10}

edges <- data %>%
  unnest_tokens(word, ccdd2) %>%
  filter(!is.na(word)) %>%
  anti_join(stop_words) %>%
  filter(nchar(word) > 2) %>%
  pairwise_count(word, linenumber, sort = TRUE, upper = FALSE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    item1 = toupper(item1),
    item2 = toupper(item2)
  )

colnames(edges) <- c("from", "to", "title")

nodes <- unique(c(edges$from, edges$to)) %>%
  as_tibble()
colnames(nodes) <- "label"
nodes$id <- nodes$label
nodes$font.size <- rep(30, nrow(nodes))

nodes <- left_join(nodes, dictionary, by = c("id" = "code")) %>%
  dplyr::distinct()
colnames(nodes)[4] <- "title"

a <- 1
b <- 20
c <- min(edges$title)
d <- max(edges$title)

edges$width <- a + ((b - a) / (d - c)) * (edges$title - c)
graph <- graph_from_data_frame(edges, directed = FALSE)
cluster <- cluster_louvain(graph)
cluster_df <- data.frame(as.list(membership(cluster)))
cluster_df <- as.data.frame(t(cluster_df))
cluster_df$label <- rownames(cluster_df)
nodes <- left_join(nodes, cluster_df, by = "label")
colnames(nodes)[5] <- "group"

visNetwork(nodes, edges, height = "500px", width = "100%") %>%
  visIgraphLayout() %>%
  visInteraction(zoomView = FALSE) %>%
  visNodes(
    shape = "dot",
    color = list(background = "#0085AF", border = "#013848", highlight = "#FF8000"),
    shadow = list(enabled = TRUE, size = 10)
  ) %>%
  visEdges(color = list(color = "#0085AF", highlight = "#C62F4B")) %>%
  visOptions(
    selectedBy = "group",
    highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE),
    nodesIdSelection = TRUE
  ) %>%
  visLayout(randomSeed = 2001)
```

Chief Complaint Correlation {data-navmenu="Term Network Graphs"} 
=======================================================================

### Chief Complaint Parsed Term Correlation Network Graph

```{r CC correlation network, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 15, fig.height = 10}

pal <- c("#003C67FF", "#4A6990FF")

# Static ggraph option
check_row <- unnested_cc_unigrams %>%
  select(
    linenumber,
    word
  ) %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  nrow()

cc_cor1 <- unnested_cc_unigrams %>%
  select(
    linenumber,
    word
  ) %>%
  group_by(word) %>%
  {if(check_row != 0) filter(., n() >= 20) else filter(., n() > 0)} %>% 
  pairwise_cor(word, linenumber, sort = TRUE) %>%
  filter(correlation > 0.15) %>%
  mutate(
    pair1 = paste(item1, item2),
    pair2 = paste(item2, item1)
  ) %>%
  filter(!pair1 %in% unnested_cc_bigrams$bigram) %>%
  filter(!pair2 %in% unnested_cc_bigrams$bigram)

cc_cor_graph <- cc_cor1 %>%
  graph_from_data_frame()

cc_cor_graph %>% 
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = pal[1], size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void() +
  labs(
    title = "Pairs of terms with at least a 0.15 correlation of appearting within the same chief complaint. Consecutive term pairs/bigrams removed.",
    caption = "Opacity of line represents magnitude of correlation"
  )
```

### Chief Complaint Parsed Term Correlation Search Table

```{r search table, echo = FALSE, warning = FALSE, message = FALSE}

cc_cor1 %>%
  select(
    `Term 1` = item1,
    `Term 2` = item2,
    `Correlation` = correlation
  ) %>%
  mutate(
    `Term 1` = toupper(`Term 1`),
    `Term 2` = toupper(`Term 2`),
    `Correlation` = format(round(`Correlation`, 2), nsmall = 2)
  ) %>%
  datatable(
    filter = list(position = "top", clear = FALSE),
    options = list(pageLength = 20)
  )

```

```{r ngram analysis, echo = FALSE, warning = FALSE, message = FALSE}

cc_unigram_analysis <- unnested_cc_unigrams %>%
  mutate(time_floor = floor_date(date, unit = "1 week")) %>%
  count(time_floor, word) %>%
  complete(word, time_floor, fill = list(n = 0)) %>%
  group_by(time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(word) %>%
  mutate(ngram_total = sum(n)) %>%
  rename(count = n) %>%
  filter(ngram_total > 30) %>%
  mutate(
    frequency = (count / time_total),
    frequency = ifelse(is.infinite(frequency), 0, frequency),
    frequency = ifelse(is.nan(frequency), 0, frequency)
  ) %>%
  nest(data = -word) %>%
  mutate(
    models = map(data, ~ glm(cbind(count, time_total - count) ~ time_floor, ., family = "binomial") %>% tidy())
  ) %>%
  unnest(models)

if (nrow(cc_unigram_analysis) > 0) {
  cc_unigram_filtered <- cc_unigram_analysis %>%
    filter(term == "time_floor") %>%
    mutate(adjusted.p.value = p.adjust(p.value)) %>%
    filter(adjusted.p.value < 0.01) %>%
    arrange(adjusted.p.value) %>%
    unnest(data) %>%
    mutate(word = toupper(word))
} else {
  cc_unigram_filtered <- cc_unigram_analysis %>%
    mutate(statistic = NA)
}

cc_bigram_analysis <- unnested_cc_bigrams %>%
  mutate(time_floor = floor_date(date, unit = "1 week")) %>%
  count(time_floor, bigram) %>%
  complete(bigram, time_floor, fill = list(n = 0)) %>%
  group_by(time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(bigram) %>%
  mutate(ngram_total = sum(n)) %>%
  rename(count = n) %>%
  filter(ngram_total > 30) %>%
  mutate(
    frequency = (count / time_total),
    frequency = ifelse(is.infinite(frequency), 0, frequency),
    frequency = ifelse(is.nan(frequency), 0, frequency)
  ) %>%
  nest(data = -bigram) %>%
  mutate(
    models = map(data, ~ glm(cbind(count, time_total - count) ~ time_floor, ., family = "binomial") %>% tidy())
  ) %>%
  unnest(models)

if (nrow(cc_bigram_analysis) > 0) {
  cc_bigram_filtered <- cc_bigram_analysis %>%
    filter(term == "time_floor") %>%
    mutate(adjusted.p.value = p.adjust(p.value)) %>%
    filter(adjusted.p.value < 0.01) %>%
    arrange(adjusted.p.value) %>%
    unnest(data) %>%
    mutate(bigram = toupper(bigram))
} else {
  cc_bigram_filtered <- cc_bigram_analysis %>%
    mutate(statistic = NA)
}

dd_unigram_analysis <- unnested_dd_unigrams %>%
  mutate(time_floor = floor_date(date, unit = "1 week")) %>%
  count(time_floor, word) %>%
  complete(word, time_floor, fill = list(n = 0)) %>%
  group_by(time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(word) %>%
  mutate(ngram_total = sum(n)) %>%
  rename(count = n) %>%
  filter(ngram_total > 30) %>%
  mutate(
    frequency = (count / time_total),
    frequency = ifelse(is.infinite(frequency), 0, frequency),
    frequency = ifelse(is.nan(frequency), 0, frequency)
  ) %>%
  nest(data = -word) %>%
  mutate(
    models = map(data, ~ glm(cbind(count, time_total - count) ~ time_floor, ., family = "binomial") %>% tidy())
  ) %>%
  unnest(models)

if (nrow(dd_unigram_analysis) > 0) {
  dd_unigram_filtered <- dd_unigram_analysis %>%
    filter(term == "time_floor") %>%
    mutate(adjusted.p.value = p.adjust(p.value)) %>%
    filter(adjusted.p.value < 0.01) %>%
    arrange(adjusted.p.value) %>%
    unnest(data) %>%
    mutate(word = toupper(word)) %>%
    inner_join(dictionary, by = c("word" = "code"))
} else {
  dd_unigram_filtered <- dd_unigram_analysis %>%
    mutate(statistic = NA)
}

dd_bigram_analysis <- unnested_dd_bigrams %>%
  mutate(time_floor = floor_date(date, unit = "1 week")) %>%
  count(time_floor, bigram) %>%
  complete(bigram, time_floor, fill = list(n = 0)) %>%
  group_by(time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(bigram) %>%
  mutate(ngram_total = sum(n)) %>%
  rename(count = n) %>%
  filter(ngram_total > 30) %>%
  mutate(
    frequency = (count / time_total),
    frequency = ifelse(is.infinite(frequency), 0, frequency),
    frequency = ifelse(is.nan(frequency), 0, frequency)
  ) %>%
  nest(data = -bigram) %>%
  mutate(
    models = map(data, ~ glm(cbind(count, time_total - count) ~ time_floor, ., family = "binomial") %>% tidy())
  ) %>%
  unnest(models)

if (nrow(dd_bigram_analysis) > 0) {
  dd_bigram_filtered <- dd_bigram_analysis %>%
    filter(term == "time_floor") %>%
    mutate(adjusted.p.value = p.adjust(p.value)) %>%
    filter(adjusted.p.value < 0.01) %>%
    arrange(adjusted.p.value) %>%
    unnest(data) %>%
    mutate(bigram = toupper(bigram)) %>%
    separate(bigram, c("code1", "code2"), remove = FALSE) %>%
    inner_join(dictionary, by = c("code1" = "code")) %>%
    inner_join(dictionary, by = c("code2" = "code")) %>%
    rename(
      description1 = description.x,
      description2 = description.y
    )
} else {
  dd_bigram_filtered <- dd_bigram_analysis %>%
    mutate(statistic = NA)
}

cc_unigrams_increasing <- cc_unigram_filtered %>%
  filter(statistic > 0)

cc_unigrams_decreasing <- cc_unigram_filtered %>%
  filter(statistic < 0)

cc_bigrams_increasing <- cc_bigram_filtered %>%
  filter(statistic > 0)

cc_bigrams_decreasing <- cc_bigram_filtered %>%
  filter(statistic < 0)

dd_unigrams_increasing <- dd_unigram_filtered %>%
  filter(statistic > 0)

dd_unigrams_decreasing <- dd_unigram_filtered %>%
  filter(statistic < 0)

dd_bigrams_increasing <- dd_bigram_filtered %>%
  filter(statistic > 0)

dd_bigrams_decreasing <- dd_bigram_filtered %>%
  filter(statistic < 0)

ht1 <- max(length(unique(cc_unigrams_increasing$word)), length(unique(dd_unigrams_increasing$word))) * 3
ht2 <- max(length(unique(cc_unigrams_decreasing$word)), length(unique(dd_unigrams_decreasing$word))) * 3

ht3 <- max(length(unique(cc_bigrams_increasing$bigram)), length(unique(dd_bigrams_increasing$bigram))) * 3
ht4 <- max(length(unique(cc_bigrams_decreasing$bigram)), length(unique(dd_bigrams_decreasing$bigram))) * 3
```

Increasing Unigrams {data-navmenu="Significant Change in Term Usage Over Time"} 
=======================================================================

Trends represent the proportion of term occurrences on a weekly time resolution. The numerator is the number of occurrences of the term in a specific week, while the denominator is the sum of all term frequencies in that week. A binomial model is fit to each time series to determine if term occurrence has changed significantly over time. Terms with a positive slope (test statistic) and adjusted p-value < 0.01 are categorized as having significant increase, while terms with a negative slope and adjusted p-value < 0.01 are categorized as having significant decrease.

Column 
-----------------------------------------------------------------------

### Change in Individual CC Unigram Trends - Increasing

```{r CC increasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht1}

pal <- c("#003C67FF", "#4A6990FF")

if (nrow(cc_unigrams_increasing) > 0) {
  tab_gg <- cc_unigrams_increasing %>%
    select(word, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        ) +
        theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"))
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("word", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      word = "Chief Complaint Unigram",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly increasing unigrams found.")
}
``` 

Column 
-----------------------------------------------------------------------

### Change in Individual DD Unigram Trends - Increasing

```{r DD increasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht1}

if (nrow(dd_unigrams_increasing) > 0) {
  tab_gg <- dd_unigrams_increasing %>%
    select(word, description, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        ) +
        theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"))
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("word", "description", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      word = "ICD-10 Unigram",
      description = "Description",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly increasing unigrams found.")
}
```

Decreasing Unigrams {data-navmenu="Significant Change in Term Usage Over Time"} 
=======================================================================

Trends represent the proportion of term occurrences on a weekly time resolution. The numerator is the number of occurrences of the term in a specific week, while the denominator is the sum of all term frequencies in that week. A binomial model is fit to each time series to determine if term occurrence has changed significantly over time. Terms with a positive slope (test statistic) and adjusted p-value < 0.01 are categorized as having significant increase, while terms with a negative slope and adjusted p-value < 0.01 are categorized as having significant decrease.

Column 
-----------------------------------------------------------------------

### Change in Individual CC Unigram Trends - Decreasing

```{r CC decreasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht2}

if (nrow(cc_unigrams_decreasing) > 0) {
  tab_gg <- cc_unigrams_decreasing %>%
    select(word, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        ) +
        theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"))
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("word", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      word = "Chief Complaint Unigram",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly decreasing unigrams found.")
}
```  

Column 
-----------------------------------------------------------------------

### Change in Individual DD Term Trends - Decreasing

```{r DD decreasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht2}

if (nrow(dd_unigrams_decreasing) > 0) {
  tab_gg <- dd_unigrams_decreasing %>%
    select(word, description, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        ) +
        theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"))
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("word", "description", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      word = "ICD-10 Unigram",
      description = "Description",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly decreasing unigrams found.")
}
```

Increasing Bigrams {data-navmenu="Significant Change in Term Usage Over Time"} 
=======================================================================

Trends represent the proportion of bigram occurrences on a weekly time resolution. The numerator is the number of occurrences of the bigram in a specific week, while the denominator is the sum of all bigram frequencies in that week. A binomial model is fit to each time series to determine if bigram occurrence has changed significantly over time. Bigrams with a positive slope (test statistic) and adjusted p-value < 0.01 are categorized as having significant increase, while bigrams with a negative slope and adjusted p-value < 0.01 are categorized as having significant decrease.

Column 
-----------------------------------------------------------------------

### Change in CC Bigram Trends - Increasing

```{r CC increasing bigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht3}

pal <- c("#003C67FF", "#4A6990FF")

if (nrow(cc_bigrams_increasing) > 0) {
  tab_gg <- cc_bigrams_increasing %>%
    select(bigram, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        ) +
        theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"))
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("bigram", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      bigram = "Chief Complaint Bigram",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly increasing bigrams found.")
}
``` 

Column 
-----------------------------------------------------------------------

### Change in DD Bigram Trends - Increasing

```{r DD increasing bigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht3}

if (nrow(dd_bigrams_increasing) > 0) {
  tab_gg <- dd_bigrams_increasing %>%
    select(bigram, description1, description2, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        )
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("bigram", "description1", "description2", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      bigram = "ICD-10 Bigram",
      description1 = "Description 1",
      description2 = "Description 2",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly increasing bigrams found.")
}
```

Decreasing Bigrams {data-navmenu="Significant Change in Term Usage Over Time"} 
=======================================================================

Trends represent the proportion of bigram occurrences on a weekly time resolution. The numerator is the number of occurrences of the bigram in a specific week, while the denominator is the sum of all bigram frequencies in that week. A binomial model is fit to each time series to determine if bigram occurrence has changed significantly over time. Bigrams with a positive slope (test statistic) and adjusted p-value < 0.01 are categorized as having significant increase, while bigrams with a negative slope and adjusted p-value < 0.01 are categorized as having significant decrease.

Column 
-----------------------------------------------------------------------

### Change in CC Bigram Trends - Decreasing

```{r CC decreasing bigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht4}

pal <- c("#003C67FF", "#4A6990FF")

if (nrow(cc_bigrams_decreasing) > 0) {
  tab_gg <- cc_bigrams_decreasing %>%
    select(bigram, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        ) +
        theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"))
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("bigram", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      bigram = "Chief Complaint Bigram",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly decreasing bigrams found.")
}
``` 

Column 
-----------------------------------------------------------------------

### Change in DD Bigram Trends - Decreasing

```{r DD decreasing bigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht4}

if (nrow(dd_bigrams_decreasing) > 0) {
  tab_gg <- dd_bigrams_decreasing %>%
    select(bigram, description1, description2, statistic, adjusted.p.value, time_floor, frequency) %>%
    mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
    nest(data = c(time_floor, frequency)) %>%
    mutate(trend = map(.x = data, .f = function(.x) {
      ggplot(data = .x) +
        geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
        scale_y_continuous(limits = c(0, NA)) +
        theme_few() +
        labs(
          x = "",
          y = ""
        )
    }))
  
  ft_gg <- tab_gg %>%
    flextable(col_keys = c("bigram", "description1", "description2", "statistic", "adjusted.p.value", "trend")) %>%
    set_header_labels(
      bigram = "ICD-10 Bigram",
      description1 = "Description 1",
      description2 = "Description 2",
      statistic = "Statistic",
      adjusted.p.value = "Adjusted p-value",
      trend = "Trend"
    ) %>%
    mk_par(j = "trend", value = as_paragraph(
      gg_chunk(value = trend, width = 4, height = 2)
    )) %>%
    theme_box() %>%
    colformat_double(digits = 2)
  
  ft_gg
} else {
  cat("No significantly decreasing bigrams found.")
}
```