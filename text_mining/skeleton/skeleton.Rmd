---
title: "Text Analysis Interactive Dashboard Template"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
description: This template is a Text Analysis Interactive Dashboard. 
  Remember to change the title to your liking.
  PLEASE Knit it with Parameters!!!
output: 
  flexdashboard::flex_dashboard:
    vertical_layout: scroll
    orientation: columns
params:
  username:
    label: "NSSP Username: "
    value: ""
    input: text
  password:
    label: "NSSP Password: "
    value: ""
    input: password
  start_date:
    label: "Enter Start Date: "
    value: !r as.Date(paste0(format(Sys.Date(), "%Y-"),"01-01"))
    input: date
  end_date:
    label: "Enter End Date: "
    value: !r Sys.Date()
    input: date
  has_been_E: 
    label: "Has Been Emergency: "
    value: true
  data_source:
    label: "Data Source: "
    value: Chief Complaint Query Validation
    input: select 
    choices: [Chief Complaint Query Validation, Facility Location (Full Details)]
  ccdd_category: 
    label: "CCDD Category: " 
    value: "All Traffic Related v1"
    input: text
  query:
    label: "ESSENCE Query: "
    value : "^;MotorVehicle;^,OR,(,(,^PED^,or,^BIKE^,or,^BICYCLE^,or,^SKATE^,or,^SKATING^,),AND,(,^VERSUS^,OR,^VS[. ]^,OR,(,^V[. ]^,ANDNOT,^[A-Z]V^,),),),OR,^motor vehicle crash^,OR,^motorcycle crash^,OR,^[;/ ]V0[2349].[19][0129]^,or,^[;/ ]V0[2349][19][0129]^,or,^[;/ ]V09.2[019]^,or,^[;/ ]V092[019]^,or,^[;/ ]V1[234].[3459]^,or,^[;/ ]V1[234][3459]^,or,^[;/ ]V19.[4-6][09]^,or,^[;/ ]V19[4-6][09]^,or,^[;/ ]V2[0-8].[3459]^,or,^[;/ ]V2[0-8][3459]^,or,^[;/ ]V29.[456][09]^,or,^[;/ ]V29[456][09]^,or,^[;/ ]V29.8[18]^,or,^[;/ ]V298[18]^,or,^[;/ ]V29.9^,or,^[;/ ]V3[0-7].[45679]^,or,^[;/ ]V3[0-7][45679]^,or,^[;/ ]V39.8[19]^,or,^[;/ ]V398[19]^,or,^[;/ ]V4[01245678].[45679]^,or,^[;/ ]V4[01245678][45679]^,or,^[;/ ]V43.[45679][1-4]^,or,^[;/ ]V43[45679][1-4]^,or,^[;/ ]V[3-7]9.[456][09]^,or,^[;/ ]V[3-7]9[456][09]^,or,^[;/ ]V[3-7]9.9^,or,^[;/ ]V[3-7]99^,or,^[;/ ]V[4-7]9.8[18]^,or,^[;/ ]V[4-7]98[18]^,or,^[;/ ]V[5-7][0-8].[45679]^,or,^[;/ ]V[5-7][0-8][45679]^,or,^[;/ ]V8[345].[0-3]^,or,^[;/ ]V8[345][0-3]^,or,^[;/ ]V86.[0-3][1234569]^,or,^[;/ ]V86[0-3][1234569]^,or,^[;/ ]V80.[345][12]^,or,^[;/ ]V80[345][12]^,or,^[;/ ]V8[12].1^,or,^[;/ ]V8[12]1^,or,^[;/ ]V87.[0-9]^,or,^[;/ ]V87[0-9]^,or,^[;/ ]V89.2^,or,^[;/ ]V892^,or,^[;/ ]Y32^,or,^[;/ ]Y0[23].0^,or,^Y0[23]0^,or,^[;/ ]Y03.8^,or,^[;/ ]Y038^,or,^[;/ ]X82.[028]^,or,^[;/ ]X82[028]^,or,^[;/ ]X81.0^,or,^[;/ ]X810^,or,^[;/ ]X82.1^,or,^[;/ ]X821^"
    input: text
---


```{r setup, include = FALSE}
## Libraries ----
library(Rnssp)
library(tidyverse)
library(tidytext)
library(kableExtra)
library(knitr) 
library(janitor)
library(wesanderson)
library(MMWRweek)
library(openxlsx)
library(lubridate)
library(grid)
library(gridExtra)
library(shiny)
library(flexdashboard)
library(plotly)
library(widyr)
library(igraph) 
library(visNetwork)
library(ggpubr)
library(ggthemes)
library(flextable)
```


```{r set_end_start_dates, echo=FALSE, message=FALSE, include=FALSE}
endDate <- format(params$end_date, "%d%b%Y")
startDate <- format(params$start_date, "%d%b%Y")
hasBeenE <- as.numeric(params$has_been_E)
```


```{r set_nssp_user_profile, echo=FALSE, message=FALSE, include=FALSE}
## Set NSSP user profile
userProfile <- Credentials$new(
  username = params$username,
  password = params$password
)
```

```{r ESSENCE data pull, echo=FALSE, message = FALSE, warning = FALSE, results = 'hide'}

ccdd_category_string <- str_replace_all(tolower(params$ccdd_category), " ", "%20")

if(params$data_source == "Chief Complaint Query Validation"){
  url <- paste0("https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate,"&ccddCategory=", ccdd_category_string, "&timeResolution=weekly&percentParam=noPercent&userId=2362&datasource=va_erccdd&aqtTarget=DataDetails&detector=nodetectordetector&startDate=", startDate, "&hasBeenE=", hasBeenE)
}else if(params$data_source == "Facility Location (Full Details)"){
  url <- paste0("https://essence2.syndromicsurveillance.org/nssp_essence/api/dataDetails?endDate=", endDate, "&percentParam=noPercent&datasource=va_hosp&startDate=", startDate, "&medicalGroupingSystem=essencesyndromes&userId=2362&aqtTarget=DataDetails&ccddCategory=", ccdd_category_string, "&geographySystem=hospital&detector=nodetectordetector&timeResolution=daily&hasBeenE=", hasBeenE, "&field=Date&field=WeekYear&field=ChiefComplaintOrig&field=ChiefComplaintParsed&field=DischargeDiagnosis&field=CCDD")
}

# Data Pull from NSSP-ESSENCE
api_data_json <- userProfile$get_api_data(url)
api_data <- api_data_json$dataDetails

tbl <- api_data %>%
  clean_names() %>%
  as_tibble() %>%
  separate(week_year, c("year", "week"), sep = "-", remove = TRUE) %>%
  mutate(
    week = as.numeric(week),
    year = as.numeric(year)
  ) %>%
  filter(!is.na(week)) %>%
  mutate(
    date = MMWRweek2Date(year, week, MMWRday = NULL),
    linenumber = row_number(), 
    month = round_date(date, "month")
  ) 

```

```{r clean text, echo = FALSE, message = FALSE, warning = FALSE, results = 'hide'}

data <- api_data %>%
  clean_text() %>% 
  separate(week_year, c("year", "week"), sep = "-", remove = TRUE) %>%
  mutate(
    week = as.numeric(week),
    year = as.numeric(year)
  ) %>%
  filter(!is.na(week)) %>%
  mutate(
    date = MMWRweek2Date(year, week, MMWRday = NULL),
    linenumber = row_number(), 
    month = round_date(date, "month")
  )

```

```{r data and dictionary import, echo = FALSE, warning = FALSE, message = FALSE}

dictionary <- openxlsx::read.xlsx("ICD10v2.xlsx") %>%
  as_tibble() %>%
  clean_names() %>%
  add_row(code = "U07.1", description = "COVID-19, virus identified") %>%
  add_row(code = "U071", description = "COVID-19, virus identified") %>%
  add_row(code = "M79.10", description = "Myalgia, unspecified site") %>%
  add_row(code = "M7910", description = "Myalgia, unspecified site") %>%
  add_row(code = "Z11.52", description = "Encounter for screening for COVID-19") %>%
  add_row(code = "Z1152", description = "Encounter for screening for COVID-19") %>%
  add_row(code = "Z20.822", description = "Contact with and (suspected) exposure to COVID-19") %>%
  add_row(code = "Z20822", description = "Contact with and (suspected) exposure to COVID-19") %>%
  add_row(code = "Z86.16", description = "Personal history of COVID-19") %>%
  add_row(code = "Z8616", description = "Personal history of COVID-19") %>%
  add_row(code = "M35.81", description = "Multisystem inflammatory syndrome (MIS)") %>%
  add_row(code = "M3581", description = "Multisystem inflammatory syndrome (MIS)") %>%
  add_row(code = "M35.89", description = "Other specified systemic involvement of connective tissue") %>%
  add_row(code = "M3589", description = "Other specified systemic involvement of connective tissue") %>%
  add_row(code = "J12.82", description = "Pneumonia due to coronavirus disease") %>%
  add_row(code = "J1282", description = "Pneumonia due to coronavirus disease") %>%
  arrange(code)

```

Background
==========================================================================

Column 
-----------------------------------------------------------------------

### Purpose  

The purpose of this interactive dashboard is to summarise the chief complaint text and diagnosis codes as part of the iterative development cycle, or as part of an initial description of the content of these fields in existing syndromes or categories. The data source used in this dashboard is the Chief Complaint Query Validation (CCQV) data source in NSSP-ESSENCE, which includes the chief complaint and discharge diagnosis fields, and does not include facility location, patient location, or other demographic information. This data source was created with the Syndromic Community of Practice (CoP) so that users can test and create new syndrome categories using a large corpus of chief complaint and diagnosis code data that includes more variation than would be present in any one site.  Some sites have opted out of contributing their data to the Query Validation data source, including Arizona, Idaho, Illinois, Marion County, Indiana, Massachusetts, North Dakota, and Ohio.

### Interactive Visualizations 

The visualizations in this dashboard include total weekly volume of encounters, the 200 most frequent n-gram frequencies of chief complaint terms and discharge diagnosis codes, and term co-occurrence network graphs for the ChiefComplaintParsed and CCDD fields. Potential clusters or groupings of terms are visualized by node color and can be selected from the "Select by group" drop down menu. All widgets were produced with the Plotly and visNetwork packages which provide hovering functionality such as displaying data point values, ICD-10 code descriptions, and co-occurrence frequencies. 

### Query Details

```{r query, echo = FALSE, warning = FALSE, message = FALSE}

query <- params$query

data.frame(Fields = "CCDD", Query = str_replace_all(query, pattern = "\\^", "\\\\^")) %>%
  kable() %>%
  kable_styling() %>%
  scroll_box()
 
```

Column 
-----------------------------------------------------------------------

### Total Number of Encounters

```{r total encounters, echo = FALSE, warning = FALSE, message = FALSE}

valueBox(nrow(data), icon = "fa-hospital")

```

### Date Range

```{r date range, echo = FALSE, warning = FALSE, message = FALSE}

range <- paste(format(as.Date(min(data$date)), "%B %d, %Y"), "to", format(as.Date(max(data$date)), "%B %d, %Y")) 

valueBox(range, icon = "fa-calendar", color = "orange")

```

### Total Weekly Volume of Encounters from Query Validation Data Source \nNSSP-ESSENCE

```{r total volume, echo = FALSE, warning = FALSE, message = FALSE}

data %>%
  count(date) %>%
  plot_ly(x = ~date, 
          y = ~n, 
          type = "scatter", 
          mode = "lines+markers",
          hoverinfo = "text",
          text = ~paste( 
            "</br><b>Date:</b>", date, 
            "</br><b>Encounters:</b>", n
          )) %>%
  layout(xaxis = list(title = "MMWR Week Date", rangemode = "tozero"), 
         yaxis = list(title = "Encounters", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE) 
  
```

Chief Complaint {data-navmenu="Character and Token Length of CC and DD Fields"} 
=======================================================================
  
Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Characters in Chief Complaint Field  

```{r mean characters CC, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths <- data %>%
  mutate(lengthCC = str_count(chief_complaint_parsed),
         tokensCC = sapply(strsplit(chief_complaint_parsed, " "), length),
         lengthDD = str_count(discharge_diagnosis),
         tokensDD = sapply(strsplit(discharge_diagnosis, " "), length)) %>%
  group_by(date) %>%
  summarise(MeanCharLengthCC = mean(lengthCC, na.rm = TRUE),
            MedianCharLengthCC = median(lengthCC, na.rm = TRUE),
            MeanTknLengthCC = mean(tokensCC, na.rm = TRUE),
            MedianTknLengthCC = median(tokensCC, na.rm = TRUE),
            MeanCharLengthDD = mean(lengthDD, na.rm = TRUE),
            MedianCharLengthDD = median(lengthDD, na.rm = TRUE),
            MeanTknLengthDD = mean(tokensDD, na.rm = TRUE),
            MedianTknLengthDD = median(tokensDD, na.rm = TRUE),
            N = n()) %>%
  ungroup()

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MeanCharLengthCC, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Mean') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Characters", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

### Weekly Median Number of Characters in Chief Complaint Field 

```{r median characters CC, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MedianCharLengthCC, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Median') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Characters", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Tokens in Chief Complaint Field 

```{r mean tokens CC, echo = FALSE, error = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MeanTknLengthCC, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Mean') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Tokens", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

### Weekly Median Number of Tokens in Chief Complaint Field 

```{r median tokens CC, echo = FALSE, error = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MedianTknLengthCC, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Mean') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Tokens", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

Discharge Diagnosis {data-navmenu="Character and Token Length of CC and DD Fields"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Characters in Discharge Diagnosis Field  

```{r mean characters DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MeanCharLengthDD, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Mean') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Characters", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

### Weekly Median Number of Characters in Discharge Diagnosis Field 

```{r median characters DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MedianCharLengthDD, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Median') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Characters", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

Column 
-----------------------------------------------------------------------

### Weekly Mean Number of Tokens in Discharge Diagnosis Field 

```{r mean tokens DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MeanTknLengthDD, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Mean') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Tokens", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

### Weekly Median Number of Tokens in Discharge Diagnosis Field 

```{r median tokens DD, echo = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

cc_dd_lengths %>% 
  plot_ly(x = ~date, 
          y = ~MedianTknLengthDD, 
          type = 'scatter', 
          mode = 'lines', 
          name = 'Mean') %>% 
  layout(xaxis = list(title = "Week"), 
         yaxis = list(title = "Tokens", rangemode = "tozero")) %>%
  config(displayModeBar = FALSE)

```

Unigram {data-navmenu="N-gram Frequencies"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Chief Complaint  

```{r CC unigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

unnested_cc_unigrams <- data %>% 
  unnest_tokens(word, chief_complaint_parsed) %>% 
  filter(word != "na") %>%
  anti_join(stop_words)

ccngram <- unnested_cc_unigrams %>%
  count(word, sort = TRUE) %>% 
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    word = str_to_upper(word),
    word = factor(word, levels = unique(word)[order(n, decreasing = TRUE)])
  )

ccngram %>%
  plot_ly(x = ~n, 
          y = ~word, 
          type = "bar", 
          orientation = "h",
          hoverinfo = "text", 
          text = ~paste(word,
                        '<br> Frequency: ', n)) %>%
          layout(title = "Top 200 Single Term Frequencies of Chief Complaint Parsed",
           xaxis = list(title = "Frequency"), 
           yaxis = list(autorange = "reversed", title = "Word")) %>%
    config(displayModeBar = FALSE)

```

Column 
-----------------------------------------------------------------------

### Discharge Diagnosis 

```{r DD unigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

unnested_dd_unigrams <- data %>% 
  unnest_tokens(word, discharge_diagnosis) %>% 
  filter(word != "2019") %>%
  anti_join(stop_words) 

ddngram <- unnested_dd_unigrams %>%
  count(word, sort = TRUE) %>% 
  ungroup() %>%
  top_n(200) %>% 
  mutate(word = toupper(word)) %>%
  left_join(dictionary, by = c("word" = "code")) %>%
  distinct() %>%
  mutate(
    word = factor(word, levels = unique(word)[order(n, decreasing = TRUE)])
  ) 

ddngram %>%
  plot_ly(x = ~n, 
          y = ~word, 
          type = "bar", 
          orientation = "h",
          hoverinfo = "text",
          text = ~paste(word, ": ", description,
                        '<br> Frequency: ', n)) %>%
    layout(title = "Top 200 Single Term Frequencies of Discharge Diagnosis",
           xaxis = list(title = "Frequency"), 
           yaxis = list(autorange = "reversed", title = "Word")) %>%
    config(displayModeBar = FALSE)

```

Bigram {data-navmenu="N-gram Frequencies"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Chief Complaint 

```{r CC bigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

ccngram <- data %>% 
  unnest_tokens(bigram, chief_complaint_parsed, token = "ngrams", n = 2) %>% 
  filter(bigram != "na") %>% 
  count(bigram, sort = TRUE) %>% 
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    bigram = str_to_upper(bigram),
    bigram = factor(bigram, levels = unique(bigram)[order(n, decreasing = TRUE)])
    )

ccngram %>%
  plot_ly(x = ~n, 
          y = ~bigram, 
          type = "bar", 
          orientation = "h",  
          hoverinfo = "text", 
          text = ~paste(bigram,
                        '<br> Frequency: ', n)) %>%
  layout(title = "Top 200 Bigram Frequencies of Chief Complaint Parsed",
         xaxis = list(title = "Frequency"), 
         yaxis = list(autorange = "reversed", title = "Bigram")) %>%
  config(displayModeBar = FALSE)

```

Column 
-----------------------------------------------------------------------

### Discharge Diagnosis

```{r DD bigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

ddngram <- data %>% 
  unnest_tokens(bigram, discharge_diagnosis, token = "ngrams", n = 2) %>% 
  filter(!is.na(bigram)) %>%
  separate(bigram, c("code1", "code2"), remove = FALSE) %>%
  filter(code1 != "2019" & code2 != "2019") %>%
  rowwise() %>%
  mutate(bigramID = list(c(code1, code2))) %>%
  mutate(bigramID = paste(sort(bigramID),  collapse = "-")) %>%
  count(bigramID, sort = TRUE) %>%
  ungroup() %>%
  top_n(200) %>% 
  slice(1:200) %>%
  separate(bigramID, c("code1", "code2"), sep = "-", remove = FALSE) %>%
  mutate(code1 = toupper(code1), 
         code2 = toupper(code2)) %>%
  mutate(bigram = paste(code1, code2, sep = " ")) %>%
  left_join(dictionary, by = c("code1" = "code")) %>%
  left_join(dictionary, by = c("code2" = "code")) %>%
  rename(description1 = description.x, 
         description2 = description.y) %>%
  mutate(bigram = factor(bigram, levels = unique(bigram)[order(n, decreasing = TRUE)])) %>%
  distinct()

ddngram %>%
  plot_ly(x = ~n, 
          y = ~bigram, 
          type = "bar", 
          orientation = "h", 
          hoverinfo = "text",
          text = ~paste(code1, ": ", description1,
                        "<br>", code2, ": ", description2, 
                        "<br> Frequency: ", n)) %>%
  layout(title = "Top 200 Bigram Frequencies of Discharge Diagnosis",
         xaxis = list(title = "Frequency"), 
         yaxis = list(autorange = "reversed", title = "Bigram")) %>%
  config(displayModeBar = FALSE)

```

Trigram {data-navmenu="N-gram Frequencies"} 
=======================================================================

Column 
-----------------------------------------------------------------------

### Chief Complaint  

```{r CC trigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

ccngram <- data %>% 
  unnest_tokens(trigram, chief_complaint_parsed, token = "ngrams", n = 3) %>% 
  filter(trigram != "na") %>% 
  count(trigram, sort = TRUE) %>% 
  top_n(200) %>%
  slice(1:200) %>%
  mutate(
    trigram = str_to_upper(trigram),
    trigram = factor(trigram, levels = unique(trigram)[order(n, decreasing = TRUE)])
  )

ccngram %>%
  plot_ly(x = ~n, 
          y = ~trigram, 
          type = "bar", 
          orientation = "h",  
          hoverinfo = "text",
          text = ~paste(trigram,
                        '<br> Frequency: ', n)) %>%
  layout(title = "Top 200 Trigram Frequencies of Chief Complaint Parsed", 
         xaxis = list(title = "Frequency"), 
         yaxis = list(autorange = "reversed", title = "Trigram")) %>%
  config(displayModeBar = FALSE)

```

Column 
-----------------------------------------------------------------------

### Discharge Diagnosis  

```{r DD trigram frequencies, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 50}

ddngram <- data %>% 
  unnest_tokens(trigram, discharge_diagnosis, token = "ngrams", n = 3) %>% 
  filter(!is.na(trigram)) %>%
  separate(trigram, c("code1", "code2", "code3"), remove = FALSE) %>%
  filter(code1 != "2019" & code2 != "2019" & code3 != "2019") %>%
  rowwise() %>%
  mutate(trigramID = list(c(code1, code2, code3))) %>%
  mutate(trigramID = paste(sort(trigramID),  collapse = "-")) %>%
  count(trigramID, sort = TRUE) %>%
  ungroup() %>%
  top_n(200) %>% 
  slice(1:200) %>%
  separate(trigramID, c("code1", "code2", "code3"), sep = "-", remove = FALSE) %>%
  mutate(code1 = toupper(code1), 
         code2 = toupper(code2), 
         code3 = toupper(code3)) %>%
  mutate(trigram = paste(code1, code2, code3, sep = " ")) %>%
  left_join(dictionary, by = c("code1" = "code")) %>%
  left_join(dictionary, by = c("code2" = "code")) %>%
  left_join(dictionary, by = c("code3" = "code")) %>%
  rename(description1 = description.x, 
         description2 = description.y,
         description3 = description) %>%
  mutate(trigram = factor(trigram, levels = unique(trigram)[order(n, decreasing = TRUE)])) %>%
  distinct()

ddngram %>%
  plot_ly(x = ~n, 
          y = ~trigram, 
          type = "bar", 
          orientation = "h", 
          hoverinfo = "text",
          text = ~paste(code1, ": ", description1,
                        "<br>", code2, ": ", description2, 
                        "<br>", code3, ": ", description3, 
                        "<br> Frequency: ", n)) %>%
  layout(title = "Top 200 Trigram Frequencies of Discharge Diagnosis",
         xaxis = list(title = "Frequency"), 
         yaxis = list(autorange = "reversed", title = "Trigram")) %>%
  config(displayModeBar = FALSE)

```

Chief Complaint {data-navmenu="Term Co-occurrence Network Graph"} 
=======================================================================

### Chief Complaint Parsed Term Co-occurrence Network Graph

```{r CC network, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 10}

edges <- unnested_cc_unigrams %>%
  pairwise_count(word, linenumber, sort=TRUE, upper=FALSE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(item1 = toupper(item1),
         item2 = toupper(item2))

colnames(edges) <- c("from", "to", "title")

nodes <- unique(c(edges$from, edges$to)) %>%
  as_tibble()
colnames(nodes) <- "label"
nodes$id <- nodes$label
nodes$font.size = rep(30, nrow(nodes))

a <- 1 
b <- 20
c <- min(edges$title)
d <- max(edges$title)

edges$width <- a + ((b - a) / (d - c))*(edges$title - c)
graph <- graph_from_data_frame(edges, directed = FALSE)
cluster <- cluster_louvain(graph)
cluster_df <- data.frame(as.list(membership(cluster)))
cluster_df <- as.data.frame(t(cluster_df))
cluster_df$label <- rownames(cluster_df)
nodes <- left_join(nodes, cluster_df, by = "label")
colnames(nodes)[4] <- "group"

visNetwork(nodes, edges, height = "500px", width = "100%") %>%
  visIgraphLayout() %>%
  visInteraction(zoomView = FALSE) %>%
  visNodes(shape = "dot",
  color = list(background = "#0085AF", border = "#013848", highlight = "#FF8000"),
  shadow = list(enabled = TRUE, size = 10)) %>%
  visEdges(color = list(color = "#0085AF", highlight = "#C62F4B")) %>%
  visOptions(selectedBy = "group",
             highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE),
             nodesIdSelection = TRUE) %>%
  visLayout(randomSeed = 2001)

```

Chief Complaint and Discharge Diagnosis {data-navmenu="Term Co-occurrence Network Graph"} 
=======================================================================

### CCDD Term Co-occurrence Network Graph

```{r CCDD network, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10, fig.height = 10}

edges <- data %>% 
  unnest_tokens(word, ccdd2) %>% 
  filter(!is.na(word)) %>%
  anti_join(stop_words) %>%
  pairwise_count(word, linenumber, sort=TRUE, upper=FALSE) %>%
  top_n(200) %>%
  slice(1:200) %>%
  mutate(item1 = toupper(item1),
         item2 = toupper(item2))

colnames(edges) <- c("from", "to", "title")

nodes <- unique(c(edges$from, edges$to)) %>%
  as_tibble()
colnames(nodes) <- "label"
nodes$id <- nodes$label
nodes$font.size = rep(30, nrow(nodes))

nodes <- left_join(nodes, dictionary, by = c("id" = "code")) %>%
  dplyr::distinct()
colnames(nodes)[4] <- "title"

a <- 1 
b <- 20
c <- min(edges$title)
d <- max(edges$title)

edges$width <- a + ((b - a) / (d - c))*(edges$title - c)
graph <- graph_from_data_frame(edges, directed = FALSE)
cluster <- cluster_louvain(graph)
cluster_df <- data.frame(as.list(membership(cluster)))
cluster_df <- as.data.frame(t(cluster_df))
cluster_df$label <- rownames(cluster_df)
nodes <- left_join(nodes, cluster_df, by = "label")
colnames(nodes)[5] <- "group"

visNetwork(nodes, edges, height = "500px", width = "100%") %>%
  visIgraphLayout() %>%
  visInteraction(zoomView = FALSE) %>%
  visNodes(shape = "dot",
  color = list(background = "#0085AF", border = "#013848", highlight = "#FF8000"),
  shadow = list(enabled = TRUE, size = 10)) %>%
  visEdges(color = list(color = "#0085AF", highlight = "#C62F4B")) %>%
  visOptions(selectedBy = "group",
             highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE),
             nodesIdSelection = TRUE) %>%
  visLayout(randomSeed = 2001) 

```

```{r ngram analysis, echo = FALSE, warning = FALSE, message = FALSE}

cc_unigram_analysis <- unnested_cc_unigrams %>%
  mutate(time_floor = floor_date(date, unit = "1 week")) %>%
  count(time_floor, word) %>%
  complete(word, time_floor, fill = list(n = 0)) %>%
  group_by(time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(word) %>%
  mutate(ngram_total = sum(n)) %>%
  rename(count = n) %>%
  filter(ngram_total > 30) %>%
  mutate(
    frequency = (count / time_total),
    frequency = ifelse(is.infinite(frequency), 0, frequency), 
    frequency = ifelse(is.nan(frequency), 0, frequency)
  ) %>%
  nest(data = -word) %>%
  mutate(
    models = map(data, ~glm(cbind(count, time_total - count) ~ time_floor, ., family = "binomial") %>% tidy)
  ) %>%
  unnest(models) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value)) %>%
  filter(adjusted.p.value < 0.01)  %>%
  arrange(adjusted.p.value) %>%
  unnest(data) %>%
  mutate(word = toupper(word))

dd_unigram_analysis <- unnested_dd_unigrams %>%
  mutate(time_floor = floor_date(date, unit = "1 week")) %>%
  count(time_floor, word) %>%
  complete(word, time_floor, fill = list(n = 0)) %>%
  group_by(time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(word) %>%
  mutate(ngram_total = sum(n)) %>%
  rename(count = n) %>%
  filter(ngram_total > 30) %>%
  mutate(
    frequency = (count / time_total),
    frequency = ifelse(is.infinite(frequency), 0, frequency), 
    frequency = ifelse(is.nan(frequency), 0, frequency)
  ) %>%
  nest(data = -word) %>%
  mutate(
    models = map(data, ~glm(cbind(count, time_total - count) ~ time_floor, ., family = "binomial") %>% tidy)
  ) %>%
  unnest(models) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value)) %>%
  filter(adjusted.p.value < 0.01)  %>%
  arrange(adjusted.p.value) %>%
  unnest(data) %>%
  mutate(word = toupper(word)) %>%
  inner_join(dictionary, by = c("word" = "code"))

cc_unigrams_increasing <- cc_unigram_analysis %>%
  filter(statistic > 0)

cc_unigrams_decreasing <- cc_unigram_analysis %>%
  filter(statistic < 0) 

dd_unigrams_increasing <- dd_unigram_analysis %>%
  filter(statistic > 0)

dd_unigrams_decreasing <- dd_unigram_analysis %>%
  filter(statistic < 0)

ht1 <- max(length(unique(cc_unigrams_increasing$word)), length(unique(dd_unigrams_increasing$word))) * 3
ht2 <- max(length(unique(cc_unigrams_decreasing$word)), length(unique(dd_unigrams_decreasing$word))) * 3

```

Increasing Unigrams {data-navmenu="Significant Change in Term Usage Over Time"} 
=======================================================================

Trends represent the proportion of term occurrences on a weekly time resolution. The numerator is the number of occurrences of the term in a specific week, while the denominator is the sum of all term frequencies in that week. A binomial model is fit to each time series to determine if term occurrence has changed significantly over time. Terms with a positive slope (test statistic) and adjusted p-value < 0.01 are categorized as having significant increase, while terms with a negative slope and adjusted p-value < 0.01 are categorized as having significant decrease.

Column 
-----------------------------------------------------------------------

### Change in Individual CC Term Trends - Increasing

```{r CC increasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht1}

pal <- c("#003C67FF", "#4A6990FF")

tab_gg <- cc_unigrams_increasing %>%
  select(word, statistic, adjusted.p.value, time_floor, frequency) %>%
  mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
  nest(data = c(time_floor, frequency)) %>%
  mutate(trend = map(.x = data, .f = function(.x){

    ggplot(data = .x) +
      geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
      scale_y_continuous(limits = c(0, NA)) +
      theme_few() +
      labs(x = "",
           y = "")
  })) 

ft_gg <- tab_gg %>%
  flextable(col_keys = c("word", "statistic", "adjusted.p.value", "trend")) %>%
  set_header_labels(
    word = "Chief Complaint Unigram", 
    statistic = "Statistic", 
    adjusted.p.value = "Adjusted p-value", 
    trend = "Trend"
  ) %>%
  mk_par(j = "trend", value = as_paragraph(
    gg_chunk(value = trend, width = 4, height = 2)
  )) %>%
  theme_box() %>%
  colformat_double(digits = 2)

ft_gg

``` 

Column 
-----------------------------------------------------------------------

### Change in Individual DD Term Trends - Increasing

```{r DD increasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht1}

tab_gg <- dd_unigram_analysis %>%
  filter(statistic > 0) %>%
  select(word, description, statistic, adjusted.p.value, time_floor, frequency) %>%
  mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
  nest(data = c(time_floor, frequency)) %>%
  mutate(trend = map(.x = data, .f = function(.x){

    ggplot(data = .x) +
      geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
      scale_y_continuous(limits = c(0, NA)) +
      theme_few() +
      labs(x = "",
           y = "")
  })) 

ft_gg <- tab_gg %>%
  flextable(col_keys = c("word", "description", "statistic", "adjusted.p.value", "trend")) %>%
  set_header_labels(
    word = "ICD-10 Unigram",
    description = "Description", 
    statistic = "Statistic", 
    adjusted.p.value = "Adjusted p-value", 
    trend = "Trend"
  ) %>%
  mk_par(j = "trend", value = as_paragraph(
    gg_chunk(value = trend, width = 4, height = 2)
  )) %>%
  theme_box()  %>%
  colformat_double(digits = 2)

ft_gg

```


Decreasing Unigrams {data-navmenu="Significant Change in Term Usage Over Time"} 
=======================================================================

Trends represent the proportion of term occurrences on a weekly time resolution. The numerator is the number of occurrences of the term in a specific week, while the denominator is the sum of all term frequencies in that week. A binomial model is fit to each time series to determine if term occurrence has changed significantly over time. Terms with a positive slope (test statistic) and adjusted p-value < 0.01 are categorized as having significant increase, while terms with a negative slope and adjusted p-value < 0.01 are categorized as having significant decrease.

Column 
-----------------------------------------------------------------------

### Change in Individual CC Term Trends - Decreasing

```{r CC decreasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht2}

tab_gg <- cc_unigram_analysis %>%
  filter(statistic < 0) %>%
  select(word, statistic, adjusted.p.value, time_floor, frequency) %>%
  mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
  nest(data = c(time_floor, frequency)) %>%
  mutate(trend = map(.x = data, .f = function(.x){

    ggplot(data = .x) +
      geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
      scale_y_continuous(limits = c(0, NA)) +
      theme_few() +
      labs(x = "",
           y = "")
  })) 

ft_gg <- tab_gg %>%
  flextable(col_keys = c("word", "statistic", "adjusted.p.value", "trend")) %>%
  set_header_labels(
    word = "Chief Complaint Unigram", 
    statistic = "Statistic", 
    adjusted.p.value = "Adjusted p-value", 
    trend = "Trend"
  ) %>%
  mk_par(j = "trend", value = as_paragraph(
    gg_chunk(value = trend, width = 4, height = 2)
  )) %>%
  theme_box() %>%
  colformat_double(digits = 2)

ft_gg

```  

Column 
-----------------------------------------------------------------------

### Change in Individual DD Term Trends - Decreasing

```{r DD decreasing unigram, echo = FALSE, message = FALSE, warning = FALSE, fig.height = ht2}

tab_gg <- dd_unigram_analysis %>%
  filter(statistic < 0) %>%
  select(word, description, statistic, adjusted.p.value, time_floor, frequency) %>%
  mutate(adjusted.p.value = format(adjusted.p.value, digits = 3, scientific = TRUE)) %>%
  nest(data = c(time_floor, frequency)) %>%
  mutate(trend = map(.x = data, .f = function(.x){

    ggplot(data = .x) +
      geom_line(aes(x = time_floor, y = frequency), color = pal[2]) +
      scale_y_continuous(limits = c(0, NA)) +
      theme_few() +
      labs(x = "",
           y = "")
  })) 

ft_gg <- tab_gg %>%
  flextable(col_keys = c("word", "description", "statistic", "adjusted.p.value", "trend")) %>%
  set_header_labels(
    word = "ICD-10 Unigram",
    description = "Description", 
    statistic = "Statistic", 
    adjusted.p.value = "Adjusted p-value", 
    trend = "Trend"
  ) %>%
  mk_par(j = "trend", value = as_paragraph(
    gg_chunk(value = trend, width = 4, height = 2)
  )) %>%
  theme_box()  %>%
  colformat_double(digits = 2)

ft_gg

```
